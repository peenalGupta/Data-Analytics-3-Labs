{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peenalGupta/Data-Analytics-3-Labs/blob/main/10_Sentiment_Analysis_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBegnwVciX3q"
      },
      "source": [
        "## Setup the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUDYEREAydsp"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, SimpleRNN, Activation, Dropout, Conv1D\n",
        "from tensorflow.keras.layers import Embedding, Flatten, LSTM, GRU\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Colab bug: https://github.com/googlecolab/colabtools/issues/3409\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda do_setlocale: \"UTF-8\""
      ],
      "metadata": {
        "id": "tSbm1JPdPRY0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2GGZkNBiUDO"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFAlVSfR-LOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0d3fb2e9-f730-4f6f-b3c2-68034eb250a3"
      },
      "source": [
        "data = pd.read_csv(\"https://storage.googleapis.com/adsa-data/sentiment-analysis/tweeter.csv\", header=None, encoding='latin-1')\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0           1                             2         3                4  \\\n",
              "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
              "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
              "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
              "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
              "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
              "\n",
              "                                                   5  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6740e8c-3689-4f54-82ec-082623931d4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6740e8c-3689-4f54-82ec-082623931d4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6740e8c-3689-4f54-82ec-082623931d4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6740e8c-3689-4f54-82ec-082623931d4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e170745-7a02-4763-8e7b-a35c7982a2ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e170745-7a02-4763-8e7b-a35c7982a2ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e170745-7a02-4763-8e7b-a35c7982a2ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 356596865,\n        \"min\": 1467810369,\n        \"max\": 2193602129,\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          2191434431,\n          1468290988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 11363,\n        \"samples\": [\n          \"Mon Apr 06 22:27:22 PDT 2009\",\n          \"Tue Apr 07 04:26:22 PDT 2009\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"NO_QUERY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18105,\n        \"samples\": [\n          \"1SEJAL1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19953,\n        \"samples\": [\n          \"Why amen't I eating proper food? I feel ill now \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "TB_zc38FjQjE",
        "outputId": "32941b82-6bd6-447f-924e-614192764096"
      },
      "source": [
        "# Check for missing values\n",
        "data.isnull().any()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "1    False\n",
              "2    False\n",
              "3    False\n",
              "4    False\n",
              "5    False\n",
              "dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBS6ajOHkBBf"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_8gm-fukIQj"
      },
      "source": [
        "We only care about the tweet text and tweet sentiment information, which stored in the 5th column and 0th column in the dataset. In the sentiment column, 0 represents negative, and 1 represents positive.\n",
        "\n",
        "We organize the data as data_X contains all the tweet text, data_y contains the labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaPV8cXIkyjR"
      },
      "source": [
        "The following code will convert the tweet text data_X to sequence format that will be feed into RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVX5M3jV_WOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed82d2e-438c-465d-d26b-39e753d81ac0"
      },
      "source": [
        "data_X = data[5]\n",
        "print(data_X)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1        is upset that he can't update his Facebook by ...\n",
            "2        @Kenichan I dived many times for the ball. Man...\n",
            "3          my whole body feels itchy and like its on fire \n",
            "4        @nationwideclass no, it's not behaving at all....\n",
            "                               ...                        \n",
            "19995    Just woke up. Having no school is the best fee...\n",
            "19996    TheWDB.com - Very cool to hear old Walt interv...\n",
            "19997    Are you ready for your MoJo Makeover? Ask me f...\n",
            "19998    Happy 38th Birthday to my boo of alll time!!! ...\n",
            "19999    happy #charitytuesday @theNSPCC @SparksCharity...\n",
            "Name: 5, Length: 20000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Label:\n",
        "*   0 -> NEGATIVE\n",
        "*   2 -> NEUTRAL\n",
        "*   4 -> POSITIVE"
      ],
      "metadata": {
        "id": "RINdPERcXARu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt_DCR2SGvGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703a7b97-280e-4f82-8848-139ae57f7af8"
      },
      "source": [
        "data_y = pd.get_dummies(data[0]).to_numpy()\n",
        "print(data_y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True False]\n",
            " [ True False]\n",
            " [ True False]\n",
            " ...\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odrbjT-ClZEn"
      },
      "source": [
        "Splitting Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBWMDqltvnHK"
      },
      "source": [
        "# TODO: Split data into train and valid sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splits Dataset into Training and Testing set\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(data_X, data_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(\"Train Data size:\", len(train_data))\n",
        "# print(\"Test Data size\", len(test_data))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "X3KasVGeR7-Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMpyUa8Dt8zH"
      },
      "source": [
        "MAX_VOCAB = 18000\n",
        "MAX_LEN = 150\n",
        "EMBED_SIZE = 200"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Tokenize inputs\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB)\n",
        "tokenizer.fit_on_texts(train_X)\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "valid_X = tokenizer.texts_to_sequences(valid_X)\n",
        "\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "JXaHmlwpCMbz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Text padding\n",
        "train_X = pad_sequences(train_X, maxlen=MAX_LEN)\n",
        "valid_X = pad_sequences(valid_X, maxlen=MAX_LEN)"
      ],
      "metadata": {
        "id": "hopnUDHbCYbW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC90NhQYRzhQ",
        "outputId": "11360816-18ac-4633-f396-06d428408218"
      },
      "source": [
        "train_X"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  687, 2036,  337],\n",
              "       [   0,    0,    0, ...,  780,  130,   36],\n",
              "       [   0,    0,    0, ...,  688,  108,   96],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 1190,  424,    9],\n",
              "       [   0,    0,    0, ...,    2,  105,  257],\n",
              "       [   0,    0,    0, ...,    2,  437,   14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gd1NpvNlfjI"
      },
      "source": [
        "## Preparing Word Embeddings using the GloVe Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale=True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "5zXNxa8I_YGg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhHyWeUz_vpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpIBFSi8oVyW",
        "outputId": "2e1a1c4a-6b1a-441b-e39f-1093afec880d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkOVxFEzkx-v",
        "outputId": "a4a439ac-acea-4f5f-fc7a-30fc8ce8881b"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load the twitter embeddings model. This model is trained on 2 billion tweets, which contains 27 billion tokens, 1.2 million vocabs.\n",
        "# might take a while\n",
        "glove_model = api.load(\"glove-twitter-200\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6didFc14I-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f3e45c-1de7-4c7d-b5b4-fee07424d78e"
      },
      "source": [
        "# calcultaete number of words\n",
        "nb_words = len(word_index) + 1\n",
        "print('All words: ', nb_words)\n",
        "\n",
        "# obtain the word embedding matrix\n",
        "embedding_matrix = np.zeros((nb_words, EMBED_SIZE))\n",
        "for word, i in word_index.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[i] = glove_model[word]\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All words:  26001\n",
            "Null word embeddings: 10327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7obYrO0MZTHN"
      },
      "source": [
        "**Explanation of the steps performed till now**\n",
        "\n",
        "Tweets: Is upset that he can't update his Facebook..\n",
        "\n",
        "Expected Input to RNN model -\n",
        "Is - Embeddings [200] (32)\n",
        "\n",
        "upset - Embeddings [200] (450)\n",
        "\n",
        "that - Embeddings [200] (43)\n",
        "\n",
        "he - Embeddings [200] (56)\n",
        "\n",
        "1. Vocabulary of all tweets: 30257 unique tokens\n",
        "2. Unique token IDs: ID (1, 2, 3, 4... for all the 30257 tokens)\n",
        "3. Tweets represented as the sequence of IDs [32 450 43 56 ...]\n",
        "\n",
        "Padding:\n",
        "\"Commonly in RNN's, we take the final output or hidden state and use this to make a prediction (or do whatever task we are trying to do).\n",
        "If we send a bunch of 0's to the RNN before taking the final output (i.e. 'post' padding as you describe), then the hidden state of the network at the final word in the sentence would likely get 'flushed out' to some extent by all the zero inputs that come after this word.\n",
        "So intuitively, this might be why pre-padding is more popular/effective.\" - [link](https://stackoverflow.com/questions/46298793/how-does-choosing-between-pre-and-post-zero-padding-of-sequences-impact-results)\n",
        "\n",
        "Padding for RNNs - [Link](https://datascience.stackexchange.com/questions/49168/padding-sequences-for-neural-sequence-models-rnns)\n",
        "\n",
        "[Paper](https://arxiv.org/abs/1903.07288)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A9N9LKhlwS_"
      },
      "source": [
        "## Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEjtnTkLl1dG"
      },
      "source": [
        "Train and evaluate the SimpleRNN, LSTM, and GRU networks on our prepared dataset.\n",
        "\n",
        "We are using the pre-trained word embeddings from the glove.twitter.27B.200d.txt data. Using the pre-trained word embeddings as weights for the Embedding layer leads to better results and faster convergence.\n",
        "\n",
        "We set each models to run 20 epochs, but we also set EarlyStopping rules to prevent overfitting. The results of the SimpleRNN, LSTM, GRU models can be seen below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QoxYEfl6zr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f9837f-4cb8-4d47-a399-a2049465ce2f"
      },
      "source": [
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(nb_words, EMBED_SIZE, weights=[embedding_matrix], input_length=MAX_LEN, trainable = False))\n",
        "\n",
        "# TODO: Add a SimpleRNN layer\n",
        "model_rnn.add(SimpleRNN(64))\n",
        "model_rnn.add(Dense(2, activation='softmax'))\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_rnn.fit(train_X, train_y, epochs=20, batch_size=120,\n",
        "          validation_data=(valid_X, valid_y), callbacks=EarlyStopping(monitor='val_accuracy', mode='max',patience=3))\n",
        "\n",
        "predictions = model_rnn.predict(valid_X)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(classification_report(valid_y.argmax(axis=1), predictions))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.6141 - loss: 0.6586 - val_accuracy: 0.7075 - val_loss: 0.5621\n",
            "Epoch 2/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7251 - loss: 0.5414 - val_accuracy: 0.7535 - val_loss: 0.5158\n",
            "Epoch 3/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7541 - loss: 0.5037 - val_accuracy: 0.7615 - val_loss: 0.5054\n",
            "Epoch 4/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7691 - loss: 0.4820 - val_accuracy: 0.6672 - val_loss: 0.6528\n",
            "Epoch 5/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7493 - loss: 0.5118 - val_accuracy: 0.7268 - val_loss: 0.5417\n",
            "Epoch 6/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7804 - loss: 0.4647 - val_accuracy: 0.7558 - val_loss: 0.5117\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77      2018\n",
            "           1       0.79      0.69      0.74      1982\n",
            "\n",
            "    accuracy                           0.76      4000\n",
            "   macro avg       0.76      0.76      0.75      4000\n",
            "weighted avg       0.76      0.76      0.75      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlA_9skrnjNk"
      },
      "source": [
        "## LSTM and GRUs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train a LSTM model by replacing the SimpleRNN layer with a LSTM layer\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(nb_words, EMBED_SIZE, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False))\n",
        "\n",
        "# Add a LSTM layer with 64 units\n",
        "model_lstm.add(LSTM(64))\n",
        "\n",
        "model_lstm.add(Dense(2, activation='softmax'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_lstm.fit(train_X, train_y, epochs=20, batch_size=120,\n",
        "          validation_data=(valid_X, valid_y), callbacks=EarlyStopping(monitor='val_accuracy', mode='max', patience=3))\n",
        "\n",
        "predictions = model_lstm.predict(valid_X)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(classification_report(valid_y.argmax(axis=1), predictions))\n",
        "\n",
        "# TODO: Print a classification report for the model\n",
        "predictions = model_lstm.predict(valid_X)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(classification_report(valid_y.argmax(axis=1), predictions)) # This line prints the classification report"
      ],
      "metadata": {
        "id": "OKvNzMFLDTKO",
        "outputId": "e91b9b07-32ad-47b8-f25f-646a9a2c5dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6737 - loss: 0.5950 - val_accuracy: 0.7602 - val_loss: 0.5004\n",
            "Epoch 2/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7607 - loss: 0.4931 - val_accuracy: 0.7692 - val_loss: 0.4828\n",
            "Epoch 3/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7732 - loss: 0.4624 - val_accuracy: 0.7722 - val_loss: 0.4761\n",
            "Epoch 4/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7854 - loss: 0.4512 - val_accuracy: 0.7533 - val_loss: 0.4983\n",
            "Epoch 5/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8026 - loss: 0.4262 - val_accuracy: 0.7772 - val_loss: 0.4742\n",
            "Epoch 6/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8172 - loss: 0.4043 - val_accuracy: 0.7695 - val_loss: 0.4874\n",
            "Epoch 7/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8231 - loss: 0.3856 - val_accuracy: 0.7775 - val_loss: 0.4860\n",
            "Epoch 8/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8419 - loss: 0.3636 - val_accuracy: 0.7757 - val_loss: 0.4957\n",
            "Epoch 9/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8575 - loss: 0.3313 - val_accuracy: 0.7728 - val_loss: 0.5156\n",
            "Epoch 10/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8755 - loss: 0.3002 - val_accuracy: 0.7703 - val_loss: 0.5380\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.78      2018\n",
            "           1       0.78      0.75      0.76      1982\n",
            "\n",
            "    accuracy                           0.77      4000\n",
            "   macro avg       0.77      0.77      0.77      4000\n",
            "weighted avg       0.77      0.77      0.77      4000\n",
            "\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.78      2018\n",
            "           1       0.78      0.75      0.76      1982\n",
            "\n",
            "    accuracy                           0.77      4000\n",
            "   macro avg       0.77      0.77      0.77      4000\n",
            "weighted avg       0.77      0.77      0.77      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train a GRU model by replacing the SimpleRNN layer with a GRU layer\n",
        "model_gru = Sequential()\n",
        "model_gru.add(Embedding(nb_words, EMBED_SIZE, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False))\n",
        "\n",
        "# Add a GRU layer with 64 units\n",
        "model_gru.add(GRU(64))\n",
        "\n",
        "model_gru.add(Dense(2, activation='softmax'))\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_gru.fit(train_X, train_y, epochs=20, batch_size=120,\n",
        "          validation_data=(valid_X, valid_y), callbacks=EarlyStopping(monitor='val_accuracy', mode='max', patience=3))\n",
        "\n",
        "\n",
        "# TODO: Print a classification report for the model\n",
        "predictions = model_gru.predict(valid_X)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(classification_report(valid_y.argmax(axis=1), predictions))"
      ],
      "metadata": {
        "id": "pFGOeicaDdIR",
        "outputId": "62eb4d89-93ce-4a27-9aa9-4d833147a302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6340 - loss: 0.6220 - val_accuracy: 0.7602 - val_loss: 0.4956\n",
            "Epoch 2/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7640 - loss: 0.4868 - val_accuracy: 0.7692 - val_loss: 0.4799\n",
            "Epoch 3/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7837 - loss: 0.4636 - val_accuracy: 0.7540 - val_loss: 0.5099\n",
            "Epoch 4/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7886 - loss: 0.4462 - val_accuracy: 0.7753 - val_loss: 0.4737\n",
            "Epoch 5/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8005 - loss: 0.4285 - val_accuracy: 0.7797 - val_loss: 0.4751\n",
            "Epoch 6/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8082 - loss: 0.4111 - val_accuracy: 0.7750 - val_loss: 0.4727\n",
            "Epoch 7/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8185 - loss: 0.3979 - val_accuracy: 0.7688 - val_loss: 0.4852\n",
            "Epoch 8/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8399 - loss: 0.3637 - val_accuracy: 0.7790 - val_loss: 0.4863\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79      2018\n",
            "           1       0.82      0.72      0.76      1982\n",
            "\n",
            "    accuracy                           0.78      4000\n",
            "   macro avg       0.78      0.78      0.78      4000\n",
            "weighted avg       0.78      0.78      0.78      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "8WxX4omTU47e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def predict(model, text):\n",
        "    start_at = time.time()\n",
        "    # Tokenize text\n",
        "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_LEN)\n",
        "    # Predict\n",
        "    score = model.predict([x_test])[0]\n",
        "\n",
        "    return {\"NEGATIVE\": score[0], \"POSITIVE\": score[1],\n",
        "       \"elapsed_time\": time.time()-start_at}"
      ],
      "metadata": {
        "id": "US8I2F97VM6Y"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Try few sentences to check the models\n",
        "predict(model_lstm, \"I feel not so good today\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedce770-7241-4881-89d1-f4c5e6b7824c",
        "id": "nanHEo8HWZgM"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NEGATIVE': 0.9528242,\n",
              " 'POSITIVE': 0.04717582,\n",
              " 'elapsed_time': 0.19471144676208496}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"I feel not so good today\",\n",
        "    \"This movie is absolutely fantastic!\",\n",
        "    \"I'm having a terrible day\",\n",
        "    \"The food was delicious and the service was excellent\",\n",
        "    \"I'm feeling really happy and excited\"\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(\"SimpleRNN Prediction:\", predict(model_rnn, sentence))\n",
        "    print(\"LSTM Prediction:\", predict(model_lstm, sentence))\n",
        "    print(\"GRU Prediction:\", predict(model_gru, sentence))\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "lXMb82M0BPqv",
        "outputId": "c70e26f6-9a8f-44aa-f3c5-23ec2bfd8d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I feel not so good today\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step\n",
            "SimpleRNN Prediction: {'NEGATIVE': 0.71729815, 'POSITIVE': 0.28270188, 'elapsed_time': 0.37378668785095215}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM Prediction: {'NEGATIVE': 0.9528242, 'POSITIVE': 0.04717582, 'elapsed_time': 0.05945849418640137}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "GRU Prediction: {'NEGATIVE': 0.82278013, 'POSITIVE': 0.17721982, 'elapsed_time': 0.13068175315856934}\n",
            "--------------------\n",
            "Sentence: This movie is absolutely fantastic!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "SimpleRNN Prediction: {'NEGATIVE': 0.34722605, 'POSITIVE': 0.6527739, 'elapsed_time': 0.05412936210632324}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "LSTM Prediction: {'NEGATIVE': 0.13861674, 'POSITIVE': 0.8613832, 'elapsed_time': 0.05575966835021973}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "GRU Prediction: {'NEGATIVE': 0.09565047, 'POSITIVE': 0.90434957, 'elapsed_time': 0.059601545333862305}\n",
            "--------------------\n",
            "Sentence: I'm having a terrible day\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "SimpleRNN Prediction: {'NEGATIVE': 0.9183872, 'POSITIVE': 0.081612825, 'elapsed_time': 0.054248809814453125}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "LSTM Prediction: {'NEGATIVE': 0.9883491, 'POSITIVE': 0.011650869, 'elapsed_time': 0.05199623107910156}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "GRU Prediction: {'NEGATIVE': 0.97144926, 'POSITIVE': 0.028550705, 'elapsed_time': 0.05201554298400879}\n",
            "--------------------\n",
            "Sentence: The food was delicious and the service was excellent\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "SimpleRNN Prediction: {'NEGATIVE': 0.15805651, 'POSITIVE': 0.8419435, 'elapsed_time': 0.053258419036865234}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LSTM Prediction: {'NEGATIVE': 0.1068064, 'POSITIVE': 0.8931936, 'elapsed_time': 0.05698394775390625}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "GRU Prediction: {'NEGATIVE': 0.103840865, 'POSITIVE': 0.8961592, 'elapsed_time': 0.07615852355957031}\n",
            "--------------------\n",
            "Sentence: I'm feeling really happy and excited\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "SimpleRNN Prediction: {'NEGATIVE': 0.22800183, 'POSITIVE': 0.77199817, 'elapsed_time': 0.06549072265625}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "LSTM Prediction: {'NEGATIVE': 0.081974894, 'POSITIVE': 0.91802514, 'elapsed_time': 0.056079864501953125}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "GRU Prediction: {'NEGATIVE': 0.22202988, 'POSITIVE': 0.7779701, 'elapsed_time': 0.05936908721923828}\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained Word Embeddings\n",
        "\n",
        "Try training the RNNs with word embeddings but without the pre-trained weight and compare the results with the pre-trained model.\n"
      ],
      "metadata": {
        "id": "S93_jWlCBFEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(nb_words, EMBED_SIZE, input_length=MAX_LEN, trainable = False))\n",
        "\n",
        "# TODO: Add a SimpleRNN layer\n",
        "model_rnn.add(SimpleRNN(64))\n",
        "model_rnn.add(Dense(2, activation='softmax'))\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_rnn.fit(train_X, train_y, epochs=20, batch_size=120,\n",
        "          validation_data=(valid_X, valid_y), callbacks=EarlyStopping(monitor='val_accuracy', mode='max',patience=3))\n",
        "\n",
        "predictions = model_rnn.predict(valid_X)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(classification_report(valid_y.argmax(axis=1), predictions))"
      ],
      "metadata": {
        "id": "thNscra7DoZC",
        "outputId": "ab483e5b-d69b-4ec2-e68c-bbc875e32d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.5156 - loss: 0.6970 - val_accuracy: 0.5412 - val_loss: 0.6873\n",
            "Epoch 2/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5824 - loss: 0.6742 - val_accuracy: 0.6008 - val_loss: 0.6596\n",
            "Epoch 3/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6224 - loss: 0.6469 - val_accuracy: 0.6033 - val_loss: 0.6632\n",
            "Epoch 4/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6480 - loss: 0.6258 - val_accuracy: 0.6313 - val_loss: 0.6386\n",
            "Epoch 5/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6635 - loss: 0.6116 - val_accuracy: 0.6263 - val_loss: 0.6499\n",
            "Epoch 6/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6780 - loss: 0.5990 - val_accuracy: 0.6275 - val_loss: 0.6480\n",
            "Epoch 7/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6922 - loss: 0.5801 - val_accuracy: 0.6285 - val_loss: 0.6568\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.68      0.65      2018\n",
            "           1       0.64      0.58      0.61      1982\n",
            "\n",
            "    accuracy                           0.63      4000\n",
            "   macro avg       0.63      0.63      0.63      4000\n",
            "weighted avg       0.63      0.63      0.63      4000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}